import torchimport torch.nn as nnimport torch.utils.data as Dataimport torchvisionimport matplotlib.pyplot as pltfrom mpl_toolkits.mplot3d import Axes3Dfrom matplotlib import cmimport numpy as npimport util# torch.manual_seed(1)    # reproducible# Hyper ParametersEPOCH = 10BATCH_SIZE = 64LR = 0.005         # learning rateDOWNLOAD_MNIST = FalseN_TEST_IMG = 5#read dataimg_list, bk_list, ipp_list, bds_list = util.read_bins("E:\\data\\PB\\A71_ET720_2PB\\20200229\\0229_A71_5_P_48.1x1_(100_99)\\17110602", 200, 200, True)diff_norm_list = []ipp_norm_list = []for i in range(len(img_list)):    diff = util.substract(img_list[i], bk_list[i])    diff_norm_list.append((diff - np.min(diff))/np.ptp(diff))    ipp_norm_list.append((ipp_list[i] - np.min(ipp_list[i]))/np.ptp(ipp_list[i]))# Data Loader for easy mini-batch return in training, the image batch shape will be (50, 1, 28, 28)torch_dataset = Data.TensorDataset(torch.FloatTensor(diff_norm_list), torch.FloatTensor(ipp_norm_list))train_loader = Data.DataLoader(dataset=torch_dataset, batch_size=BATCH_SIZE, shuffle=True)depth = 200class AutoEncoder(nn.Module):    def __init__(self):        super(AutoEncoder, self).__init__()        self.encoder = nn.Sequential(         # input shape (1, 200, 200)            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=2, padding=1),            nn.ReLU(),            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=2, padding=1),            nn.ReLU(),            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),            nn.ReLU(),            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1),            nn.ReLU(),            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),            nn.ReLU(),            nn.Conv2d(in_channels=64, out_channels=depth, kernel_size=5, stride=1, padding=2),            nn.ReLU(),        )        self.decoder = nn.Sequential(            nn.Conv2d(in_channels=depth, out_channels=64, kernel_size=5, stride=1, padding=2),            nn.ReLU(),            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),            nn.ReLU(),            nn.Upsample(scale_factor=(2, 2), mode="bilinear"),            nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3, stride=1, padding=1),            nn.ReLU(),            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),            nn.ReLU(),            nn.Upsample(scale_factor=(2, 2), mode="bilinear"),            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),            nn.ReLU(),            nn.Upsample(scale_factor=(2, 2), mode="bilinear"),            nn.Conv2d(in_channels=32, out_channels=1, kernel_size=3, stride=1, padding=1),            nn.ReLU(),        )    def forward(self, x):        encoded = self.encoder(x)        decoded = self.decoder(encoded)        return encoded, decodedautoencoder = AutoEncoder()print(autoencoder)  # net architectureoptimizer = torch.optim.Adam(autoencoder.parameters(), lr=LR)loss_func = nn.MSELoss()# initialize figuref, a = plt.subplots(3, N_TEST_IMG, figsize=(5, 3))plt.ion()   # continuously plot# original data (first row) for viewinginput_data = torch_dataset[:N_TEST_IMG][0]target_data = torch_dataset[:N_TEST_IMG][1]for i in range(N_TEST_IMG):    a[0][i].imshow(input_data.data.numpy()[i], cmap='gray')    a[1][i].imshow(target_data.data.numpy()[i], cmap='gray')    # a[0][i].set_xticks(())    # a[0][i].set_yticks(())plt.show()for epoch in range(EPOCH):    for step, (x, b_label) in enumerate(train_loader):        b_x = x.view(-1, 1, 200, 200)   # batch x, shape (batch, 28*28)        b_y = x.view(-1, 1, 200, 200)   # batch y, shape (batch, 28*28)        encoded, decoded = autoencoder(b_x)        loss = loss_func(decoded, b_y)      # mean square error        optimizer.zero_grad()               # clear gradients for this training step        loss.backward()                     # backpropagation, compute gradients        optimizer.step()                    # apply gradients        if step % 100 == 0:            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy())            # plotting decoded image (second row)            _, decoded_data = autoencoder(input_data.view(-1, 1, 200, 200))            for i in range(N_TEST_IMG):                a[2][i].clear()                a[2][i].imshow(np.reshape(decoded_data.data.numpy()[i], (200, 200)), cmap='gray')                a[2][i].set_xticks(()); a[1][i].set_yticks(())            plt.draw(); plt.pause(0.05)plt.ioff()plt.show()# # visualize in 3D plot# view_data = train_data.train_data[:200].view(-1, 200*200).type(torch.FloatTensor)/255.# encoded_data, _ = autoencoder(view_data)# fig = plt.figure(2); ax = Axes3D(fig)# X, Y, Z = encoded_data.data[:, 0].numpy(), encoded_data.data[:, 1].numpy(), encoded_data.data[:, 2].numpy()# values = train_data.train_labels[:200].numpy()# for x, y, z, s in zip(X, Y, Z, values):#     c = cm.rainbow(int(255*s/9)); ax.text(x, y, z, s, backgroundcolor=c)# ax.set_xlim(X.min(), X.max()); ax.set_ylim(Y.min(), Y.max()); ax.set_zlim(Z.min(), Z.max())# plt.show()