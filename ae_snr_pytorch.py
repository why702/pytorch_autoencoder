import torchimport torch.nn as nnimport torch.utils.data as Dataimport torchvisionfrom torch.autograd import Variableimport matplotlib.pyplot as pltfrom mpl_toolkits.mplot3d import Axes3Dfrom matplotlib import cmimport numpy as npimport util# Hyper ParametersEPOCH = 10000BATCH_SIZE = 64LR = 0.005         # learning rateN_TEST_IMG = 5use_cuda = torch.cuda.is_available()device = torch.device('cuda:0' if use_cuda else 'cpu')# device = torch.device('cpu')#read dataimg_list, bk_list, ipp_list, bds_list = util.read_bins("D:\\data\\a71\\2PB\\0229\\0229_A71_5_P_48.1x1_(100_99)\\17110602", 200, 200, True)diff_norm_list = []ipp_norm_list = []for i in range(len(img_list)):    diff = util.substract(img_list[i], bk_list[i])    diff_norm_list.append((diff - np.min(diff))/np.ptp(diff))    ipp_norm_list.append((ipp_list[i] - np.min(ipp_list[i]))/np.ptp(ipp_list[i]))# Data Loader for easy mini-batch return in training, the image batch shape will be (50, 1, 28, 28)torch_dataset = Data.TensorDataset(torch.FloatTensor(diff_norm_list), torch.FloatTensor(ipp_norm_list))train_loader = Data.DataLoader(dataset=torch_dataset, batch_size=BATCH_SIZE, shuffle=True)depth = 200class AutoEncoder(nn.Module):    def __init__(self):        super(AutoEncoder, self).__init__()        self.encoder = nn.Sequential(         # input shape (1, 200, 200)            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=2, padding=1),            nn.ReLU(),            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=2, padding=1),            nn.ReLU(),            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),            nn.ReLU(),            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1),            nn.ReLU(),            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),            nn.ReLU(),            nn.Conv2d(in_channels=64, out_channels=depth, kernel_size=5, stride=1, padding=2),            nn.ReLU(),        )        self.decoder = nn.Sequential(            nn.Conv2d(in_channels=depth, out_channels=64, kernel_size=5, stride=1, padding=2),            nn.ReLU(),            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),            nn.ReLU(),            nn.Upsample(scale_factor=(2, 2), mode="bilinear", align_corners=True),            nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3, stride=1, padding=1),            nn.ReLU(),            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),            nn.ReLU(),            nn.Upsample(scale_factor=(2, 2), mode="bilinear", align_corners=True),            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),            nn.ReLU(),            nn.Upsample(scale_factor=(2, 2), mode="bilinear", align_corners=True),            nn.Conv2d(in_channels=32, out_channels=1, kernel_size=3, stride=1, padding=1),            nn.ReLU(),        )    def forward(self, x):        encoded = self.encoder(x)        decoded = self.decoder(encoded)        return encoded, decodeddef to_var(x):    x = Variable(x)    if use_cuda:        x = x.to(device)    return xautoencoder = AutoEncoder()autoencoder = autoencoder.to(device)# print(autoencoder)  # net architectureoptimizer = torch.optim.Adam(autoencoder.parameters(), lr=LR)loss_func = nn.MSELoss().to(device)# # Print model's state_dict# print("Model's state_dict:")# for param_tensor in autoencoder.state_dict():#     print(param_tensor, "\t", autoencoder.state_dict()[param_tensor].size())## # Print optimizer's state_dict# print("Optimizer's state_dict:")# for var_name in optimizer.state_dict():#     print(var_name, "\t", optimizer.state_dict()[var_name])# initialize figuref, a = plt.subplots(3, N_TEST_IMG, figsize=(5, 3))plt.ion()   # continuously plotfor epoch in range(EPOCH):    for step, (x, b_label) in enumerate(train_loader):        x = to_var(x)        b_label = to_var(b_label)        b_x = x.view(-1, 1, 200, 200)        b_y = b_label.view(-1, 1, 200, 200)        autoencoder.train()        encoded, decoded = autoencoder(b_x)        loss = loss_func(decoded, b_y)      # mean square error        optimizer.zero_grad()               # clear gradients for this training step        loss.backward()                     # backpropagation, compute gradients        optimizer.step()                    # apply gradients        if step % 1000 == 0:            print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(                epoch, step * len(x), len(train_loader.dataset),                100. * step / len(train_loader),                loss.data / len(x)))            # plotting decoded image            for i in range(N_TEST_IMG):                a[0][i].clear()                a[0][i].imshow(np.reshape(b_x.data.cpu().numpy()[i], (200, 200)), cmap='gray')                a[1][i].clear()                a[1][i].imshow(np.reshape(b_y.data.cpu().numpy()[i], (200, 200)), cmap='gray')                a[2][i].clear()                a[2][i].imshow(np.reshape(decoded.data.cpu().numpy()[i], (200, 200)), cmap='gray')            plt.draw()            plt.pause(0.05)plt.ioff()plt.show()# # visualize in 3D plot# view_data = train_data.train_data[:200].view(-1, 200*200).type(torch.FloatTensor)/255.# encoded_data, _ = autoencoder(view_data)# fig = plt.figure(2); ax = Axes3D(fig)# X, Y, Z = encoded_data.data[:, 0].numpy(), encoded_data.data[:, 1].numpy(), encoded_data.data[:, 2].numpy()# values = train_data.train_labels[:200].numpy()# for x, y, z, s in zip(X, Y, Z, values):#     c = cm.rainbow(int(255*s/9)); ax.text(x, y, z, s, backgroundcolor=c)# ax.set_xlim(X.min(), X.max()); ax.set_ylim(Y.min(), Y.max()); ax.set_zlim(Z.min(), Z.max())# plt.show()